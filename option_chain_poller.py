#!/usr/bin/env python3
"""
upstox_ws_feed.py

Resilient WebSocket client for Upstox Market Data Feed (V3-style).
- Requires UPSTOX_ACCESS_TOKEN in env.
- If you have MarketData.proto compiled to marketdata_pb2.py, set USE_PROTO=True to decode binary payloads.
- Provides add_instruments / remove_instruments functions and a on_tick(callback) hook.
"""

import os
import time
import json
import logging
import asyncio
import ssl
import threading
from urllib.parse import urljoin
import requests
import random

# choose your websocket client
import websockets  # pip install websockets

# Optional: protobuf decoding. If you compile MarketData.proto into marketdata_pb2.py, set USE_PROTO=True
USE_PROTO = True
try:
    if USE_PROTO:
        import marketdata_pb2  # generated by protoc from MarketData.proto
except Exception as e:
    logging.warning("Proto import failed: %s. Binary payloads will be logged raw. Set USE_PROTO=False to silence.", e)
    USE_PROTO = False

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")

# ---------- Configuration (ENV) ----------
UPSTOX_ACCESS_TOKEN = os.getenv("UPSTOX_ACCESS_TOKEN") or ""
# Confirm the correct authorize endpoint from Upstox docs for your account
MARKET_FEED_AUTHORIZE_URL = os.getenv("MARKET_FEED_AUTHORIZE_URL") or "https://api.upstox.com/v3/market-data-feed/authorize"

# Tune these:
RECONNECT_BASE_DELAY = float(os.getenv("RECONNECT_BASE_DELAY") or 1.0)
RECONNECT_MAX_DELAY = float(os.getenv("RECONNECT_MAX_DELAY") or 60.0)
DEFAULT_SUBSCRIBE_BATCH = int(os.getenv("DEFAULT_SUBSCRIBE_BATCH") or 100)  # how many instruments to include in one 'subscribe' message
WS_READ_TIMEOUT = int(os.getenv("WS_READ_TIMEOUT") or 60)  # seconds to wait for a message before considering connection unhealthy
HEARTBEAT_INTERVAL = int(os.getenv("HEARTBEAT_INTERVAL") or 25)  # if the server expects heartbeats

if not UPSTOX_ACCESS_TOKEN:
    logging.error("Set UPSTOX_ACCESS_TOKEN in environment and re-run.")
    raise SystemExit(1)

# ---------- Utility helpers ----------
def get_authorized_ws_url():
    """
    Call authorize endpoint to get a signed websocket URL.
    Response shape varies by provider; adjust parsing according to your Upstox response.
    Expected: JSON with {'data': {'socket_url': 'wss://...'}} or similar.
    """
    headers = {"Accept": "application/json", "Authorization": f"Bearer {UPSTOX_ACCESS_TOKEN}"}
    try:
        r = requests.get(MARKET_FEED_AUTHORIZE_URL, headers=headers, timeout=10)
        r.raise_for_status()
        j = r.json()
        # find field - adapt if your response differs
        # common shapes: { "data": { "socket_url": "wss://..." } }
        if isinstance(j, dict):
            d = j.get("data") or j
            # try several common keys
            url = d.get("socket_url") or d.get("socketUrl") or d.get("endpoint") or d.get("ws_url")
            if url:
                logging.info("Authorized websocket URL obtained.")
                return url
        logging.error("Unexpected authorize response shape: %s", j)
    except Exception as e:
        logging.exception("Failed to obtain authorized websocket URL: %s", e)
    return None

# ---------- WebSocket client class ----------
class UpstoxWSClient:
    """
    Resilient WebSocket client:
    - background thread runs asyncio loop
    - subscribe/unsubscribe instrument_key strings
    - on_tick callback receives decoded messages: on_tick(message_dict)
    """
    def __init__(self, on_tick_callback=None):
        self._loop = None
        self._thread = None
        self.ws = None
        self._closing = False
        self.on_tick = on_tick_callback or (lambda msg: logging.info("Tick: %s", msg))
        self.subscriptions = set()   # instrument_key strings
        self._pending_subscribe = set()
        self._pending_unsubscribe = set()
        self._lock = threading.Lock()
        self._connected_event = threading.Event()

    def start(self):
        """Start background thread that runs the asyncio websocket client."""
        if self._thread and self._thread.is_alive():
            return
        self._closing = False
        self._thread = threading.Thread(target=self._run_loop, daemon=True)
        self._thread.start()
        logging.info("UpstoxWSClient started background thread.")

    def stop(self):
        """Stop the client."""
        self._closing = True
        if self._loop:
            fut = asyncio.run_coroutine_threadsafe(self._close_ws(), self._loop)
            try:
                fut.result(timeout=5)
            except Exception:
                pass
        if self._thread:
            self._thread.join(timeout=5)
        logging.info("UpstoxWSClient stopped.")

    def add_instruments(self, keys):
        """Public: add instrument_key or list of keys to subscribe (thread-safe)."""
        if isinstance(keys, str):
            keys = [keys]
        with self._lock:
            for k in keys:
                if k not in self.subscriptions:
                    self._pending_subscribe.add(k)

    def remove_instruments(self, keys):
        if isinstance(keys, str):
            keys = [keys]
        with self._lock:
            for k in keys:
                if k in self.subscriptions:
                    self._pending_unsubscribe.add(k)

    def _run_loop(self):
        self._loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self._loop)
        self._loop.run_until_complete(self._main_loop())

    async def _close_ws(self):
        if self.ws:
            try:
                await self.ws.close()
            except:
                pass

    async def _main_loop(self):
        backoff = RECONNECT_BASE_DELAY
        while not self._closing:
            ws_url = get_authorized_ws_url()
            if not ws_url:
                logging.warning("No ws url; backing off %.1fs", backoff)
                await asyncio.sleep(backoff + random.random()*0.5)
                backoff = min(backoff * 2, RECONNECT_MAX_DELAY)
                continue

            try:
                ssl_ctx = ssl.create_default_context()
                logging.info("Connecting to WS: %s ...", ws_url[:80])
                async with websockets.connect(ws_url, ssl=ssl_ctx, max_size=None, ping_interval=None) as ws:
                    self.ws = ws
                    backoff = RECONNECT_BASE_DELAY
                    self._connected_event.set()
                    logging.info("WebSocket connected.")

                    # start background tasks: heartbeat sender and consumer
                    consumer_task = asyncio.create_task(self._consumer_loop(ws))
                    heartbeat_task = asyncio.create_task(self._heartbeat_loop(ws))

                    # initial subscribe pending keys
                    await self._flush_pending_subscriptions(ws)

                    done, pending = await asyncio.wait(
                        [consumer_task, heartbeat_task],
                        return_when=asyncio.FIRST_EXCEPTION,
                    )
                    for t in pending:
                        t.cancel()
            except websockets.ConnectionClosed as cc:
                logging.warning("WebSocket connection closed: %s", cc)
            except Exception as e:
                logging.exception("WebSocket error: %s", e)

            # clean state & backoff before reconnect
            self._connected_event.clear()
            self.ws = None
            if self._closing:
                break
            sleep_for = backoff + random.random() * 0.5
            logging.info("Reconnecting after %.1fs...", sleep_for)
            await asyncio.sleep(sleep_for)
            backoff = min(backoff * 2, RECONNECT_MAX_DELAY)

    async def _heartbeat_loop(self, ws):
        """Optional: send heartbeat or ping if required by server; placeholder."""
        try:
            while True:
                await asyncio.sleep(HEARTBEAT_INTERVAL)
                # If server expects a special heartbeat JSON, send here.
                try:
                    await ws.ping()
                except Exception as e:
                    logging.debug("Heartbeat ping failed: %s", e)
        except asyncio.CancelledError:
            return

    async def _consumer_loop(self, ws):
        """Receive messages and handle dynamic subscribe/unsubscribe requests."""
        try:
            while True:
                # flush any pending subs/unsubs before waiting - helps dynamic control
                await self._flush_pending_subscriptions(ws)
                try:
                    raw = await asyncio.wait_for(ws.recv(), timeout=WS_READ_TIMEOUT)
                except asyncio.TimeoutError:
                    logging.warning("WS read timeout (%ds). Reconnecting...", WS_READ_TIMEOUT)
                    # force reconnect by raising
                    raise websockets.ConnectionClosed(1006, "read timeout")
                if isinstance(raw, (bytes, bytearray)):
                    await self._handle_binary_message(raw)
                else:
                    await self._handle_text_message(raw)
        except asyncio.CancelledError:
            return

    async def _flush_pending_subscriptions(self, ws):
        """Send subscribe/unsubscribe messages for pending sets."""
        # copy and clear pending sets under lock
        with self._lock:
            subs = list(self._pending_subscribe)
            unsubs = list(self._pending_unsubscribe)
            self._pending_subscribe.clear()
            self._pending_unsubscribe.clear()

        # send unsubscribe first
        if unsubs:
            msg = {
                "action": "unsubscribe",   # adjust key names per docs
                "instruments": unsubs
            }
            try:
                await ws.send(json.dumps(msg))
                logging.info("Sent unsubscribe for %d instruments.", len(unsubs))
                # reflect in subscriptions set
                with self._lock:
                    for k in unsubs:
                        self.subscriptions.discard(k)
            except Exception as e:
                logging.warning("Failed to send unsubscribe: %s", e)

        if subs:
            # chunk subscribe into batches to respect server limits
            for i in range(0, len(subs), DEFAULT_SUBSCRIBE_BATCH):
                batch = subs[i:i+DEFAULT_SUBSCRIBE_BATCH]
                msg = {
                    "action": "subscribe",   # adjust per Upstox spec
                    "instruments": batch
                }
                try:
                    await ws.send(json.dumps(msg))
                    logging.info("Sent subscribe for %d instruments.", len(batch))
                    with self._lock:
                        for k in batch:
                            self.subscriptions.add(k)
                except Exception as e:
                    logging.warning("Failed to send subscribe: %s", e)
                    # if subscribe fails, put them back to pending set to retry later
                    with self._lock:
                        for k in batch:
                            self._pending_subscribe.add(k)

    async def _handle_text_message(self, raw):
        logging.debug("WS text: %s", raw)
        # typical server messages: acks, unsubscribes, errors, heartbeats - parse as JSON if possible
        try:
            j = json.loads(raw)
            # handle possible subscription ack or error
            if j.get("type") == "subscription_ack":
                logging.info("Subscription ack: %s", j)
            elif j.get("type") == "error":
                logging.warning("Server error: %s", j)
            else:
                # generic text message - forward to callback
                self.on_tick(j)
        except Exception:
            logging.debug("WS text not JSON: %s", raw)

    async def _handle_binary_message(self, raw):
        logging.debug("WS binary message len=%d", len(raw))
        if USE_PROTO:
            try:
                # Upstox may use a wrapper message (example: FeedResponse). Adjust per your compiled proto.
                fb = marketdata_pb2.FeedResponse()
                fb.ParseFromString(raw)
                # Convert proto to dict for ease of use (you can tailor which fields to send)
                msg = _proto_to_dict(fb)
                self.on_tick(msg)
            except Exception as e:
                logging.exception("Proto parse failed: %s", e)
                # fallback: pass binary length
                self.on_tick({"binary_len": len(raw)})
        else:
            # No proto available: just expose raw bytes length and hex snippet
            snippet = raw[:64].hex()
            self.on_tick({"binary_len": len(raw), "snippet": snippet})

def _proto_to_dict(fb):
    """
    Convert parsed FeedResponse proto to a Python dict.
    Customize to extract the fields you need (e.g., ticks, ltp, oi, iv, timestamp).
    This implementation is illustrative and must be adapted to your proto schema.
    """
    out = {}
    try:
        # example fields - rename depending on your proto
        if hasattr(fb, "message_type"):
            out["message_type"] = fb.message_type
        # if fb has repeated fields 'ticks'
        if hasattr(fb, "ticks"):
            out["ticks"] = []
            for t in fb.ticks:
                # Example tick fields - adjust
                tick = {}
                if hasattr(t, "instrument_key"):
                    tick["instrument_key"] = getattr(t, "instrument_key")
                if hasattr(t, "ltp"):
                    tick["ltp"] = getattr(t, "ltp")
                if hasattr(t, "open_interest"):
                    tick["oi"] = getattr(t, "open_interest")
                out["ticks"].append(tick)
    except Exception as e:
        logging.exception("proto->dict convert error: %s", e)
    return out

# ---------- Example usage ----------
if __name__ == "__main__":
    # Example on_tick callback: print summarized ticks
    def on_tick(msg):
        # msg is either dict from proto conversion or raw info
        logging.info("ON_TICK: %s", msg)

    client = UpstoxWSClient(on_tick_callback=on_tick)
    client.start()

    # Wait for connect (with timeout)
    if not client._connected_event.wait(timeout=10):
        logging.warning("Didn't connect within 10s - continuing, client will keep trying in background.")

    # Example: add instruments from your cached instruments file or set manually
    # Use the instrument_key strings from your instruments JSON, e.g. "NSE_FO|50858"
    sample_keys = [
        "NSE_FO|50858",  # Nifty FO instrument example
        "NSE_FO|52539",  # TCS FO example (replace with actual keys from your cache)
    ]
    client.add_instruments(sample_keys)

    try:
        # keep main thread alive - client runs on background thread
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logging.info("Stopping client...")
        client.stop()
